{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the ABCD imaging data\n",
    "\n",
    "In the previous data exercises you have download and interacted with the [ABCD 3.0 release](https://nda.nih.gov/abcd/query/abcd-curated-annual-release-3.0.html). While there are many measures derived from the imaging data within the pre-packaged tabulated data, you may have noticed that the full set of MRI images are not included in this release.\n",
    "\n",
    "As stated on [NDA's website](https://nda.nih.gov/abcd/query/abcd-curated-annual-release-3.0.html): \n",
    "\n",
    "\"The raw MRI images and the minimally processed imaging files are over 100TB in size which may make data transfer difficult. \"\n",
    "\n",
    "The data are stored on [Amazon Simple Storage Service (s3)](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html) servers. \n",
    "\n",
    "There are multiple routes to obtaining the full imaging data, we'll focus on the following two:\n",
    "1. Using links from the [fmriresults01](https://nda.nih.gov/data_structure.html?short_name=fmriresults01) structure\n",
    "2. Using the [nda-abcd-s3-downloader](https://github.com/DCAN-Labs/nda-abcd-s3-downloader)\n",
    "\n",
    "Both routes involve creating a data package through the NDA, downloading a manifest file, parsing the manifest file, and finally downloading the data.\n",
    "\n",
    "For brevity, the exercises in this notebook will guide you through downloading the resting state and T1w data from 5 subjects using each of the above download methods. You will need active NDA credentials and an ABCD DUC to download the data.\n",
    "\n",
    "**A Note about GUIDs and BIDS**\n",
    "\n",
    "[From the NDA](https://nda.nih.gov/s/guid/nda-guid.html): \"The Global Unique Identifier (GUID) is a subject ID allowing researchers to share data specific to a study participant without exposing personally identifiable information (PII) and match participants across labs and research data repositories.\"\n",
    "\n",
    "The GUID's format is `NDAR_INVXXXXXXXX`, where `XXXXXXXX` is a random string of numbers and uppercase letters. The standard GUID format is *not* [BIDS compatible](https://bids-specification.readthedocs.io/en/stable/02-common-principles.html#file-name-structure). In BIDS, the underscore character is reserved to separate key:value entities (eg, `key1-value1_key2-value2`, `sub-01_task-rest`). For the BIDS imaging data on the NDA, the underscore in the GUID has been removed (ie, `NDARINVXXXXXXXX`), but be aware that you might need to do a string replace operation to remove the underscore from the GUIDs in the tabulated data to match the GUIDs in the BIDS imaging data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Downloading the data using the fmriresults01 structure\n",
    "\n",
    "The general workflow on the NDA is to add data to your Filter Cart and then create a Data Package from the filter. Here we will create a Data Package from the *fmriresults01* data structure. See Getting Image Volumes [here](https://nda.nih.gov/abcd/query/abcd-release-faqs.html) for more info on the *fmriresults01* structure.\n",
    "\n",
    "**NOTE**: The `fmriresults01.txt` file is distributed in the ABCD 3.0 Release. So if you've already downnloaded that, then you could use that file. If so, you can skip to step 13.\n",
    "\n",
    "1. Let's begin at the [NDA's front page](https://nda.nih.gov/). Select **Get Data** > **Get Data**\n",
    "\n",
    "<img src=\"./screenshots/nda_frontpage.png\" width=\"900\" />\n",
    "\n",
    "***\n",
    "\n",
    "2. On the **NDA Query Tool**'s menu, select **Data Structures**. Then enter \"fmriresults01\" into the Text Search field and hit enter.\n",
    "\n",
    "<img src=\"./screenshots/nda_query.png\" width=\"900\" />\n",
    "\n",
    "***\n",
    "\n",
    "3. Click the **Processed MRI Data** link, which will open the structure. Then select **Add to Filter Cart** in the lower left corner.\n",
    "\n",
    "<img src=\"./screenshots/add_filter_cart.png\" width=\"150\" />\n",
    "\n",
    "Your Filter Cart will take a few minutes to update. Make yourself some tea. Once it is finished, you should see the following.\n",
    "\n",
    "<img src=\"./screenshots/filter_cart.png\" width=\"400\" />\n",
    "\n",
    "(Sample size may vary depending on when you are working through this exercise)\n",
    "\n",
    "***\n",
    "\n",
    "4. In the Filter Cart, select **Create Data Package/Add Data to Study**, which will take you to the Data Packaging Page.\n",
    "\n",
    "5. On the Data Packaging Page, select **Create Data Package**.\n",
    "\n",
    "<img src=\"./screenshots/create_data_package.png\" width=\"200\" />\n",
    "\n",
    "6. If you are not logged into the NDA, this will prompt you to log in with your credientials. After, you will see a menu to define your Data Package. Give it a short name and ensure that **Include Associated Data Files** is *unchecked*. Otherwise, the Data Package will contain the all images in *fmriresults*. It will be faster and more flexible to only download the pointers to the data and not the data istself. When you are finished entering this information, click **Create Data Package**.\n",
    "\n",
    "<img src=\"./screenshots/create_menu.png\" width=\"300\" />\n",
    "\n",
    "***\n",
    "\n",
    "7. You will see a window that confirms that your package was initiated. Click the link to navigate to your Dashboard.\n",
    "\n",
    "<img src=\"./screenshots/package_created.png\" width=\"350\" />\n",
    "\n",
    "***\n",
    "\n",
    "8. In the drop down menu on the Data Package Dashboard, select **My Data Packages**. You should see the Data Package you just created. It will take a few minutes to move from the \"Creating Package\" status to \"Ready to Download\". Maybe refill your tea. In the below image **ABCDndar** is the Data Package we just created. **ABCDdcan** will be created in the second section of this exercise.\n",
    "\n",
    "<img src=\"./screenshots/create_dash.png\" width=\"350\" />\n",
    "\n",
    "<img src=\"./screenshots/ready_dash.png\" width=\"350\" />\n",
    "\n",
    "***\n",
    "\n",
    "9. Once the Data Package is ready to download, we can use the [NDA tools](https://github.com/NDAR/nda-tools) to download it. The NDA tools are already installed and ready to use on the ABCD-ReproNim JupyterHub. The relevant command will be `downloadcmd`. Let's see what options `downloadcmd` has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running NDATools Version 0.2.3\n",
      "Opening log: /home/jovyan/NDAValidationResults/debug_log_20210304T184400.txt\n",
      "usage: downloadcmd <S3_path_list>\n",
      "\n",
      "This application allows you to enter a list of aws S3 paths and will download\n",
      "the files to your drive in your home folder. Alternatively, you may enter a\n",
      "packageID, an NDA data structure file or a text file with s3 links, and the\n",
      "client will download all files from the S3 links listed. Please note, the\n",
      "maximum transfer limit of data is 5TB at one time.\n",
      "\n",
      "positional arguments:\n",
      "  <S3_path_list>        Will download all S3 files to your local drive\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -dp, --package        Flags to download all S3 files in package.\n",
      "  -t, --txt             Flags that a text file has been entered from where to\n",
      "                        download S3 files.\n",
      "  -ds, --datastructure  Flags that a data structure text file has been entered\n",
      "                        from where to download S3 files.\n",
      "  -u <arg>, --username <arg>\n",
      "                        NDA username\n",
      "  -p <arg>, --password <arg>\n",
      "                        NDA password\n",
      "  -r <arg>, --resume <arg>\n",
      "                        Flags to restart a download process. If you already\n",
      "                        have some files downloaded, you must enter the\n",
      "                        directory where they are saved.\n",
      "  -d <arg>, --directory <arg>\n",
      "                        Enter an alternate full directory path where you would\n",
      "                        like your files to be saved.\n",
      "  -wt <arg>, --workerThreads <arg>\n",
      "                        Number of worker threads\n",
      "  -v, --verbose         Option to print out more detailed messages as the\n",
      "                        program runs.\n"
     ]
    }
   ],
   "source": [
    "! downloadcmd -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the `!` in the code cell of a Jupyter notebook means to execute that command using shell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "10. Our first usage of `downloadcmd` will use the Package ID to download the associated package files. Let's put the ABCDndar package into it's own directory. If you have already set up your NDA credentials to download the ABCD 3.0 Release, then `downloadcmd` will use the already stored credentials.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/jovyan/ABCDndar’: File exists\n",
      "Running NDATools Version 0.2.3\n",
      "Opening log: /home/jovyan/NDAValidationResults/debug_log_20210304T185714.txt\n"
     ]
    }
   ],
   "source": [
    "! mkdir /home/jovyan/ABCDndar\n",
    "! downloadcmd 1186278 -dp -d /home/jovyan/ABCDndar # number is the data package ID from ndar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "11. Once the download is complete, we can list the files. The relevant file is `fmriresults01.txt`, which contains information about each image in this structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datastructure_manifest.txt  fmriresults01.txt\t package_info.txt\n",
      "experiments\t\t    guid_pseudoguid.txt  README.pdf\n"
     ]
    }
   ],
   "source": [
    "! ls /home/jovyan/ABCDndar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "12. `fmriresults01.txt` is a tab-separated table that contains information about corresponding image files. Let's read this table into python so that we can parse and choose only the image files we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fmri = pd.read_csv('/home/jovyan/ABCDndar/fmriresults01.txt', sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "\n",
    "13. Let's look at the structure and contents of the `fmriresults01.txt`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_id</th>\n",
       "      <th>fmriresults01_id</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>subjectkey</th>\n",
       "      <th>src_subject_id</th>\n",
       "      <th>origin_dataset_id</th>\n",
       "      <th>interview_date</th>\n",
       "      <th>interview_age</th>\n",
       "      <th>sex</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>...</th>\n",
       "      <th>qc_outcome</th>\n",
       "      <th>derived_files</th>\n",
       "      <th>scan_type</th>\n",
       "      <th>img03_id2</th>\n",
       "      <th>file_source2</th>\n",
       "      <th>session_det</th>\n",
       "      <th>image_history</th>\n",
       "      <th>manifest</th>\n",
       "      <th>image_description</th>\n",
       "      <th>collection_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>collection_id</td>\n",
       "      <td>fmriresults01_id</td>\n",
       "      <td>dataset_id</td>\n",
       "      <td>The NDAR Global Unique Identifier (GUID) for r...</td>\n",
       "      <td>Subject ID how it's defined in lab/project</td>\n",
       "      <td>Origin dataset Id</td>\n",
       "      <td>Date on which the interview/genetic test/sampl...</td>\n",
       "      <td>Age in months at the time of the interview/tes...</td>\n",
       "      <td>Sex of the subject</td>\n",
       "      <td>ID for the Experiment/settings/run</td>\n",
       "      <td>...</td>\n",
       "      <td>Provide information on the conclusion of the q...</td>\n",
       "      <td>An archive of the files produced by the pipeline</td>\n",
       "      <td>Type of Scan</td>\n",
       "      <td>Corresponds to row_id in image03 data structur...</td>\n",
       "      <td>File name/location, 2</td>\n",
       "      <td>session details</td>\n",
       "      <td>Image history,f.e. transformations steps and o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Image description, i.e. DTI, fMRI, Fast SPGR, ...</td>\n",
       "      <td>collection_title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2099</td>\n",
       "      <td>448</td>\n",
       "      <td>10764</td>\n",
       "      <td>NDARUC212ALG</td>\n",
       "      <td>10235701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/25/2016</td>\n",
       "      <td>300</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>s3://NDAR_Central_1/submission_11664/home-nfs/...</td>\n",
       "      <td>MR structural (T1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDoC Constructs: Neural Substrates, Heritabili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2099</td>\n",
       "      <td>449</td>\n",
       "      <td>10764</td>\n",
       "      <td>NDARLB157TKZ</td>\n",
       "      <td>10235702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/25/2016</td>\n",
       "      <td>300</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>s3://NDAR_Central_1/submission_11664/home-nfs/...</td>\n",
       "      <td>MR structural (T1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDoC Constructs: Neural Substrates, Heritabili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2099</td>\n",
       "      <td>450</td>\n",
       "      <td>10764</td>\n",
       "      <td>NDARHA308FFG</td>\n",
       "      <td>10383701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/28/2016</td>\n",
       "      <td>360</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>s3://NDAR_Central_1/submission_11664/home-nfs/...</td>\n",
       "      <td>MR structural (T1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDoC Constructs: Neural Substrates, Heritabili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2099</td>\n",
       "      <td>451</td>\n",
       "      <td>10764</td>\n",
       "      <td>NDARBE334JDM</td>\n",
       "      <td>10383702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/28/2016</td>\n",
       "      <td>360</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>s3://NDAR_Central_1/submission_11664/home-nfs/...</td>\n",
       "      <td>MR structural (T1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDoC Constructs: Neural Substrates, Heritabili...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   collection_id  fmriresults01_id  dataset_id  \\\n",
       "0  collection_id  fmriresults01_id  dataset_id   \n",
       "1           2099               448       10764   \n",
       "2           2099               449       10764   \n",
       "3           2099               450       10764   \n",
       "4           2099               451       10764   \n",
       "\n",
       "                                          subjectkey  \\\n",
       "0  The NDAR Global Unique Identifier (GUID) for r...   \n",
       "1                                       NDARUC212ALG   \n",
       "2                                       NDARLB157TKZ   \n",
       "3                                       NDARHA308FFG   \n",
       "4                                       NDARBE334JDM   \n",
       "\n",
       "                               src_subject_id  origin_dataset_id  \\\n",
       "0  Subject ID how it's defined in lab/project  Origin dataset Id   \n",
       "1                                    10235701                NaN   \n",
       "2                                    10235702                NaN   \n",
       "3                                    10383701                NaN   \n",
       "4                                    10383702                NaN   \n",
       "\n",
       "                                      interview_date  \\\n",
       "0  Date on which the interview/genetic test/sampl...   \n",
       "1                                         01/25/2016   \n",
       "2                                         01/25/2016   \n",
       "3                                         01/28/2016   \n",
       "4                                         01/28/2016   \n",
       "\n",
       "                                       interview_age                 sex  \\\n",
       "0  Age in months at the time of the interview/tes...  Sex of the subject   \n",
       "1                                                300                   F   \n",
       "2                                                300                   F   \n",
       "3                                                360                   M   \n",
       "4                                                360                   M   \n",
       "\n",
       "                        experiment_id  ...  \\\n",
       "0  ID for the Experiment/settings/run  ...   \n",
       "1                                 NaN  ...   \n",
       "2                                 NaN  ...   \n",
       "3                                 NaN  ...   \n",
       "4                                 NaN  ...   \n",
       "\n",
       "                                          qc_outcome  \\\n",
       "0  Provide information on the conclusion of the q...   \n",
       "1                                               pass   \n",
       "2                                               pass   \n",
       "3                                               pass   \n",
       "4                                               pass   \n",
       "\n",
       "                                       derived_files           scan_type  \\\n",
       "0   An archive of the files produced by the pipeline        Type of Scan   \n",
       "1  s3://NDAR_Central_1/submission_11664/home-nfs/...  MR structural (T1)   \n",
       "2  s3://NDAR_Central_1/submission_11664/home-nfs/...  MR structural (T1)   \n",
       "3  s3://NDAR_Central_1/submission_11664/home-nfs/...  MR structural (T1)   \n",
       "4  s3://NDAR_Central_1/submission_11664/home-nfs/...  MR structural (T1)   \n",
       "\n",
       "                                           img03_id2           file_source2  \\\n",
       "0  Corresponds to row_id in image03 data structur...  File name/location, 2   \n",
       "1                                                NaN                    NaN   \n",
       "2                                                NaN                    NaN   \n",
       "3                                                NaN                    NaN   \n",
       "4                                                NaN                    NaN   \n",
       "\n",
       "       session_det                                      image_history  \\\n",
       "0  session details  Image history,f.e. transformations steps and o...   \n",
       "1              NaN                                                NaN   \n",
       "2              NaN                                                NaN   \n",
       "3              NaN                                                NaN   \n",
       "4              NaN                                                NaN   \n",
       "\n",
       "  manifest                                  image_description  \\\n",
       "0      NaN  Image description, i.e. DTI, fMRI, Fast SPGR, ...   \n",
       "1      NaN                                                NaN   \n",
       "2      NaN                                                NaN   \n",
       "3      NaN                                                NaN   \n",
       "4      NaN                                                NaN   \n",
       "\n",
       "                                    collection_title  \n",
       "0                                   collection_title  \n",
       "1  RDoC Constructs: Neural Substrates, Heritabili...  \n",
       "2  RDoC Constructs: Neural Substrates, Heritabili...  \n",
       "3  RDoC Constructs: Neural Substrates, Heritabili...  \n",
       "4  RDoC Constructs: Neural Substrates, Heritabili...  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmri.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the first row contains a detailed description of the column. We won't need to include this in our parsing, so we can drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_id</th>\n",
       "      <th>fmriresults01_id</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>subjectkey</th>\n",
       "      <th>src_subject_id</th>\n",
       "      <th>origin_dataset_id</th>\n",
       "      <th>interview_date</th>\n",
       "      <th>interview_age</th>\n",
       "      <th>sex</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>...</th>\n",
       "      <th>qc_outcome</th>\n",
       "      <th>derived_files</th>\n",
       "      <th>scan_type</th>\n",
       "      <th>img03_id2</th>\n",
       "      <th>file_source2</th>\n",
       "      <th>session_det</th>\n",
       "      <th>image_history</th>\n",
       "      <th>manifest</th>\n",
       "      <th>image_description</th>\n",
       "      <th>collection_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2099</td>\n",
       "      <td>448</td>\n",
       "      <td>10764</td>\n",
       "      <td>NDARUC212ALG</td>\n",
       "      <td>10235701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/25/2016</td>\n",
       "      <td>300</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>s3://NDAR_Central_1/submission_11664/home-nfs/...</td>\n",
       "      <td>MR structural (T1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDoC Constructs: Neural Substrates, Heritabili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2099</td>\n",
       "      <td>449</td>\n",
       "      <td>10764</td>\n",
       "      <td>NDARLB157TKZ</td>\n",
       "      <td>10235702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/25/2016</td>\n",
       "      <td>300</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>s3://NDAR_Central_1/submission_11664/home-nfs/...</td>\n",
       "      <td>MR structural (T1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDoC Constructs: Neural Substrates, Heritabili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2099</td>\n",
       "      <td>450</td>\n",
       "      <td>10764</td>\n",
       "      <td>NDARHA308FFG</td>\n",
       "      <td>10383701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/28/2016</td>\n",
       "      <td>360</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>s3://NDAR_Central_1/submission_11664/home-nfs/...</td>\n",
       "      <td>MR structural (T1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDoC Constructs: Neural Substrates, Heritabili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2099</td>\n",
       "      <td>451</td>\n",
       "      <td>10764</td>\n",
       "      <td>NDARBE334JDM</td>\n",
       "      <td>10383702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/28/2016</td>\n",
       "      <td>360</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>s3://NDAR_Central_1/submission_11664/home-nfs/...</td>\n",
       "      <td>MR structural (T1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDoC Constructs: Neural Substrates, Heritabili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2099</td>\n",
       "      <td>452</td>\n",
       "      <td>10764</td>\n",
       "      <td>NDARUP674KX9</td>\n",
       "      <td>10119501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/30/2016</td>\n",
       "      <td>288</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>pass</td>\n",
       "      <td>s3://NDAR_Central_1/submission_11664/home-nfs/...</td>\n",
       "      <td>MR structural (T1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDoC Constructs: Neural Substrates, Heritabili...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  collection_id fmriresults01_id dataset_id    subjectkey src_subject_id  \\\n",
       "1          2099              448      10764  NDARUC212ALG       10235701   \n",
       "2          2099              449      10764  NDARLB157TKZ       10235702   \n",
       "3          2099              450      10764  NDARHA308FFG       10383701   \n",
       "4          2099              451      10764  NDARBE334JDM       10383702   \n",
       "5          2099              452      10764  NDARUP674KX9       10119501   \n",
       "\n",
       "  origin_dataset_id interview_date interview_age sex experiment_id  ...  \\\n",
       "1               NaN     01/25/2016           300   F           NaN  ...   \n",
       "2               NaN     01/25/2016           300   F           NaN  ...   \n",
       "3               NaN     01/28/2016           360   M           NaN  ...   \n",
       "4               NaN     01/28/2016           360   M           NaN  ...   \n",
       "5               NaN     01/30/2016           288   F           NaN  ...   \n",
       "\n",
       "  qc_outcome                                      derived_files  \\\n",
       "1       pass  s3://NDAR_Central_1/submission_11664/home-nfs/...   \n",
       "2       pass  s3://NDAR_Central_1/submission_11664/home-nfs/...   \n",
       "3       pass  s3://NDAR_Central_1/submission_11664/home-nfs/...   \n",
       "4       pass  s3://NDAR_Central_1/submission_11664/home-nfs/...   \n",
       "5       pass  s3://NDAR_Central_1/submission_11664/home-nfs/...   \n",
       "\n",
       "            scan_type img03_id2 file_source2 session_det image_history  \\\n",
       "1  MR structural (T1)       NaN          NaN         NaN           NaN   \n",
       "2  MR structural (T1)       NaN          NaN         NaN           NaN   \n",
       "3  MR structural (T1)       NaN          NaN         NaN           NaN   \n",
       "4  MR structural (T1)       NaN          NaN         NaN           NaN   \n",
       "5  MR structural (T1)       NaN          NaN         NaN           NaN   \n",
       "\n",
       "  manifest image_description  \\\n",
       "1      NaN               NaN   \n",
       "2      NaN               NaN   \n",
       "3      NaN               NaN   \n",
       "4      NaN               NaN   \n",
       "5      NaN               NaN   \n",
       "\n",
       "                                    collection_title  \n",
       "1  RDoC Constructs: Neural Substrates, Heritabili...  \n",
       "2  RDoC Constructs: Neural Substrates, Heritabili...  \n",
       "3  RDoC Constructs: Neural Substrates, Heritabili...  \n",
       "4  RDoC Constructs: Neural Substrates, Heritabili...  \n",
       "5  RDoC Constructs: Neural Substrates, Heritabili...  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmri = fmri.drop([0])\n",
    "fmri.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "14. We do not need most of the information in this table. The relevant columns are `file_source`, which contains the s3 links to the raw DICOM images and `derived_files` which contains the s3 links to the minimally preprocessed images. Here we will focus on downloading the minimally processed files in `derived_files`. We will create a dataframe that contains the s3 links and other relevant fields so that we can filter the s3 links. Explore other columns of this table to see the processing steps that has been applied to the `derived_files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>derived_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://NDAR_Central_1/submission_11664/home-nfs/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3://NDAR_Central_1/submission_11664/home-nfs/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s3://NDAR_Central_1/submission_11664/home-nfs/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s3://NDAR_Central_1/submission_11664/home-nfs/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s3://NDAR_Central_1/submission_11664/home-nfs/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       derived_files\n",
       "1  s3://NDAR_Central_1/submission_11664/home-nfs/...\n",
       "2  s3://NDAR_Central_1/submission_11664/home-nfs/...\n",
       "3  s3://NDAR_Central_1/submission_11664/home-nfs/...\n",
       "4  s3://NDAR_Central_1/submission_11664/home-nfs/...\n",
       "5  s3://NDAR_Central_1/submission_11664/home-nfs/..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new data frame from the derived_files column\n",
    "s3_derv = fmri.loc[:,['derived_files']] \n",
    "# view dataframe\n",
    "s3_derv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.count of                                             derived_files\n",
      "1       s3://NDAR_Central_1/submission_11664/home-nfs/...\n",
      "2       s3://NDAR_Central_1/submission_11664/home-nfs/...\n",
      "3       s3://NDAR_Central_1/submission_11664/home-nfs/...\n",
      "4       s3://NDAR_Central_1/submission_11664/home-nfs/...\n",
      "5       s3://NDAR_Central_1/submission_11664/home-nfs/...\n",
      "...                                                   ...\n",
      "642624                                                NaN\n",
      "642625                                                NaN\n",
      "642626                                                NaN\n",
      "642627                                                NaN\n",
      "642628                                                NaN\n",
      "\n",
      "[642628 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "# number of rows in the derived_columns dataframe\n",
    "total_rows = s3_derv.count\n",
    "print(total_rows) # 642628 rows; end seems to have a lot of NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the format of the s3 links to see how we could parse this for filtering:\n",
    "\n",
    "*s3://NDAR_Central_4/submission_32739/NDARINVXXXXXXXX_baselineYear1Arm1_ABCD-MPROC-SST-fMRI_XXXXXXXXXXXXXX.tgz*\n",
    "\n",
    "- *s3://NDAR_Central_4/submission_32739* is the location of the data on the s3 server\n",
    "- *NDARINVXXXXXXXX* is the GUID\n",
    "- *baselineYear1Arm1* is the session\n",
    "- *ABCD-MPROC-SST-fMRI* is the scan type information\n",
    "- The number at the end of the file is the acqusition date/time\n",
    "- *.tgz* is the TAR archive file extension\n",
    "\n",
    "We can use python's ability to split strings to parse these strings so that we can filter by GUID, session, and scan type. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s3:',\n",
       " '',\n",
       " 'NDAR_Central_4',\n",
       " 'submission_32739',\n",
       " 'NDARINVXXXXXXXX_baselineYear1Arm1_ABCD-MPROC-SST-fMRI_XXXXXXXXXXXXXX.tgz']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 's3://NDAR_Central_4/submission_32739/NDARINVXXXXXXXX_baselineYear1Arm1_ABCD-MPROC-SST-fMRI_XXXXXXXXXXXXXX.tgz'\n",
    "example.split('/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code splits the `example` string into a list of strings at every occurence of `/`.\n",
    "\n",
    "`.split` only operates on strings, but we have an entire column of strings we want to split. Here we can leverage python's list comprehension to iterate through each string.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-df3e20943f18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms3_derv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'derived_files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-df3e20943f18>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms3_derv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'derived_files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "test_split = [i.split('/') for i in s3_derv['derived_files']]\n",
    "test_split[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code submits the same split operation to every item in the `s3_derv['derived_files']` data frame we created above. You could also complete this with a regular `for` loop, but list comprehension is cleaner and more efficient.\n",
    "\n",
    "We can leverage string splitting and list comprehension to parse each s3 link into a corresponding GUID, session, and scan type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-63c2591ca0fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms3_derv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'guid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms3_derv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'derived_files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get the GUID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ms3_derv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'session'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms3_derv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'derived_files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get the session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ms3_derv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scan'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms3_derv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'derived_files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get the scan type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ms3_derv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-63c2591ca0fe>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms3_derv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'guid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms3_derv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'derived_files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get the GUID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ms3_derv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'session'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms3_derv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'derived_files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get the session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ms3_derv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scan'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms3_derv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'derived_files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# get the scan type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ms3_derv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "s3_derv['guid'] = [i.split('/')[-1].split('_')[0] for i in s3_derv['derived_files']] # get the GUID\n",
    "s3_derv['session'] = [i.split('/')[-1].split('_')[1] for i in s3_derv['derived_files']] # get the session\n",
    "s3_derv['scan'] = [i.split('/')[-1].split('_')[2].split('-',1)[-1] for i in s3_derv['derived_files']] # get the scan type\n",
    "\n",
    "s3_derv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
